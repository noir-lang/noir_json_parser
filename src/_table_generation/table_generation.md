# Table Generation Documentation

## Overview
The JSON parser uses lookup tables to avoid branching logic and reduce gate count. These tables are generated from `src/_table_generation/make_tables.nr`.

## Generation Process
Tables are generated by simulating all possible input combinations from basic hardcoded tables and recording the expected outputs.

## TOKEN_FLAGS_TABLE
Maps (token, context) pairs to parsing flags:
- `create_json_entry`: Whether to create a JSON entry for this token, set to true if token is literal/number/string(not key)/end of array/object
- `is_end_of_object_or_array`: Whether token ends an object/array
- `is_start_of_object_or_array`: Whether token starts an object/array
- `new_context`: What context to switch to, object is 0, array is 1
- `is_key_token`: Whether token is a key
- `is_value_token`: Whether token is a value, set to True for string_token, numeric_token, and literal_token
- `preserve_num_entries`: boolean flag that controls whether the current token should preserve the existing count of entries at the current depth or reset/increment it. 1 for tokens like NO_TOKEN, KEY_TOKEN, STRING_TOKEN, NUMERIC_TOKEN, LITERAL_TOKEN
0 for tokens like OBJECT_START_TOKEN, ARRAY_START_TOKEN, OBJECT_END_TOKEN, ARRAY_END_TOKEN

## JSON_CAPTURE_TABLE
Maps (escape_flag, scan_mode, ascii) to scanning actions:
- `scan_token`: Next capture mode based on current capture mode, can be grammar_capture([,{,comma,},],:)/string_capture/literal_capture/numeric_capture/error_capture. For example, if currently we are in string capture, and character is ", then scan_token will be set to grammar_capture because we are at end of string, back to grammar scan. If we are in numeric scan, and current character is not 0-9, then we are back to grammar scan as we expect the number has ended.
- `push_transcript`: Whether to add token to transcript: in grammar mode: true for all structual elements[,{,comma,},],:. In string_capture, true for ", which signals string end. In numeric/literal_capture, true for space, \t, \n, \r, ", and comma. Note the first scan will not pick up numerics or literals because we don't know when they end, so we need to rely on capture_missing_tokens function.
- `increase_length`: Whether to extend current token, always false for grammar_capture, true for 0-9 in numeric capture, all characters except for " in string_capture, all letters in true, false, null in literal_capture
- `is_potential_escape_sequence`: true if current token is / in string_capture mode
